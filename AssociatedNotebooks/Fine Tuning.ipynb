{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning\n",
    "\n",
    "We are going to try and fine tune a FCN classifier so to segment cells from histopathology scans. Our implementation is based on the implementation based on FCN.  \n",
    "\n",
    "\n",
    "The fine tuning wil be addressed in four steps. Preparing the data in the form of blobs, so as to be caffee compatible but also in three model training. We will train with a 32 stride, take the parameters and plug them into a finer 16 stride model, and finally the same protocole is used to go a 8 stride finner model.\n",
    "\n",
    "We will use the pre-train models available in the caffee zoo. We will remove each final layer and fine tune it via back propagation. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Preparing the data\n",
    "\n",
    "Under the library caffee, data is provided to model under the form of blobs. A blob is a 4 dimensinal array where each channels represents: (num, channel, height, width). We will be providing cell segmentation data from histopathology slides. \n",
    "It can accept several types: HDF5, LMDB, etc..\n",
    "Lets create an LMDB file to feed the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 40\n",
      "2 / 40\n",
      "3 / 40\n",
      "4 / 40\n",
      "5 / 40"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naylor/Python_pkg/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.\n",
      "  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\n",
      "/home/naylor/Python_pkg/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.\n",
      "  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\n",
      "/home/naylor/Python_pkg/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.\n",
      "  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\n",
      "/home/naylor/anaconda/lib/python2.7/site-packages/skimage/util/dtype.py:110: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6 / 40\n",
      "7 / 40\n",
      "8 / 40\n",
      "9 / 40\n",
      "10 / 40\n",
      "11 / 40\n",
      "12 / 40\n",
      "13 / 40\n",
      "14 / 40\n",
      "15 / 40\n",
      "16 / 40\n",
      "17 / 40\n",
      "18 / 40\n",
      "19 / 40\n",
      "20 / 40\n",
      "21 / 40\n",
      "22 / 40\n",
      "23 / 40\n",
      "24 / 40\n",
      "25 / 40\n",
      "26 / 40\n",
      "27 / 40\n",
      "28 / 40\n",
      "29 / 40\n",
      "30 / 40\n",
      "31 / 40\n",
      "32 / 40\n",
      "33 / 40\n",
      "34 / 40\n",
      "35 / 40\n",
      "36 / 40\n",
      "37 / 40\n",
      "38 / 40\n",
      "39 / 40\n",
      "40 / 40\n"
     ]
    }
   ],
   "source": [
    "from DataToLMDB import MakeLMDB\n",
    "import ImageTransf as Transf\n",
    "\n",
    "path = '/home/naylor/Bureau/ToAnnotate'\n",
    "\n",
    "output_dir = path + '/lmdb'\n",
    "\n",
    "enlarge = False ## create symetry if the image becomes black ? \n",
    "\n",
    "transform_list = [Transf.Identity(),\n",
    "                  Transf.Rotation(45, enlarge=enlarge), \n",
    "                  Transf.Rotation(90, enlarge=enlarge),\n",
    "                  Transf.Rotation(135, enlarge=enlarge),\n",
    "                  Transf.Flip(0),\n",
    "                  Transf.Flip(1),\n",
    "                  Transf.OutOfFocus(5),\n",
    "                  Transf.OutOfFocus(10),\n",
    "                  Transf.ElasticDeformation(0, 30, num_points = 4),\n",
    "                  Transf.ElasticDeformation(0, 30, num_points = 4)]\n",
    "\n",
    "MakeLMDB(path, output_dir, transform_list, val_num = 2, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the 32 stride model: Pascal voc example\n",
    "\n",
    "The architecture and pre-trained weight parameters can be found on the FCN github page. The architecture is based on the famous AlexNet implementation, the authors performed \"net surgery\" to transform the fully connected layers (final layers of the AlexNet model) into fully convolutionnal layers. These layers have the particularity of accepting any given size of inputs. Once these layers \"convoloutionnized\" , they added an upsampling and a deconvolution layer as to improve the accuracy of the model, indeed, AlexNet models provided the \"what\" but does not initially provide the where. Bridges were also added in order to combine low lever features to higher level features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
